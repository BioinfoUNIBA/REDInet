{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64b16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023-2024 Pietro Luca Mazzacuva <pietroluca.mazzacuva@unicampus.it>\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, pysam, gzip, subprocess, shlex, time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def give_inputs(cell_line):\n",
    "    \n",
    "    files_path = \"/lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/{}\".format(cells)\n",
    "    \n",
    "    if cell_line == \"HEK293T\":  \n",
    "        samples = [[\"outTable_599710609\", \"outTable_905657585\", \"outTable_208420383\"],\n",
    "                   [\"outTable_572868058\", \"outTable_364841872\", \"outTable_814257267\"],\n",
    "                   [\"outTable_110067244\", \"outTable_597789462\", \"outTable_530905096\"]]\n",
    "\n",
    "        rmsk_file = \"rmsk_hg38.sorted.gtf.gz\"\n",
    "        refseq_file = \"hg38.110.ncbiRefSeq.sorted.gtf.gz\"\n",
    "\n",
    "    elif cell_line == \"HEK\":\n",
    "        samples = [[\"outTable_724242056\", \"outTable_816573740\"],\n",
    "                   [\"outTable_580067564\", \"outTable_718392497\"],\n",
    "                   [\"outTable_181728208\", \"outTable_854894021\"]]\n",
    "        rmsk_file = \"rmsk.sorted.gtf.gz\"\n",
    "        refseq_file = \"hg19.ncbiRefSeq.sorted.gtf.gz\"\n",
    "\n",
    "    else:\n",
    "        samples = [[\"outTable_192318299\", \"outTable_436061877\"],\n",
    "                   [\"outTable_535670354\", \"outTable_396704193\"],\n",
    "                   [\"outTable_773331943\", \"outTable_302610513\"]]\n",
    "        rmsk_file = \"rmsk.sorted.gtf.gz\"\n",
    "        refseq_file = \"hg19.ncbiRefSeq.sorted.gtf.gz\"\n",
    "    \n",
    "    return samples, rmsk_file, refseq_file, files_path\n",
    "\n",
    "def extraction(prefix,  AG_min, AGfreq_threshold, cov_threshold, interval):    \n",
    "    \n",
    "    starttime = datetime.now()\n",
    "\n",
    "    editing = []\n",
    "    with gzip.open(prefix+\".gz\") as redi:\n",
    "        for c,l in enumerate(redi):\n",
    "            line = l.decode(\"utf-8\").rstrip().split(\"\\t\")\n",
    "            if line[0].find(\"chr\") != -1:\n",
    "                if line[4] != \"-\":\n",
    "                    if int(line[4]) >= cov_threshold:\n",
    "                        if line[2] == \"A\":\n",
    "                            if line[7] == \"AG\":    \n",
    "                                AG_rna = eval(line[6])[2]/sum(eval(line[6]))\n",
    "                                if AG_rna >= AGfreq_threshold:\n",
    "                                    if eval(line[6])[2] >= AG_min:\n",
    "                                        editing.append(line)\n",
    "                          \n",
    "            if c % 50000000 == 0:\n",
    "                print(f\"\\tSites evaluated: {c}\")\n",
    "    print(\"Total evaluated rows:\", c)\n",
    "    editing = pd.DataFrame(editing)\n",
    "    print(\"Total extracted Candidates Editing sites for current sample:\", editing.shape[0])\n",
    "    stoptime = datetime.now()\n",
    "    print(f\"[{datetime.now()}] Extraction of Editing Candidates finished for current sample. Elapsed time: {stoptime-starttime}.\")\n",
    "    columns = [\"Region\", \"Position\", \"Ref\", \"Strand\", \"Cov\", \"Qual\", \"Bases\", \"AllSubs\", \"Freq\", \"gCov\", \"gQual\", \"g[A,C,G,T]\", \"gAllSubs\", \"gFreq\"]\n",
    "    editing.columns = columns\n",
    "    print(f\"[{datetime.now()}] Starting extraction of intervals.\")\n",
    "    ohe = OneHotEncoder()\n",
    "    ohe.fit(np.array([\"A\", \"C\", \"G\", \"T\"]).reshape(-1, 1))\n",
    "\n",
    "    intervals = []\n",
    "    starttime_preds = datetime.now()\n",
    "    total_extracted = 0\n",
    "    features_extracted_filepath = prefix+ \"_feature_vectors.tsv\"\n",
    "    features_extracted = open(features_extracted_filepath, \"w\")\n",
    "\n",
    "    df = editing.query(\"Region != 'chrM'\")\n",
    "    print(f\"[{datetime.now()}] Loading reditable with tabix and pysam:\", prefix)\n",
    "    start_time = datetime.now()\n",
    "    srr = pysam.TabixFile(prefix+\".gz\")\n",
    "    with tqdm(total=df.shape[0], position=0, leave=True) as pbar:\n",
    "        for site in df.itertuples():\n",
    "            start = int(site.Position) - ((interval-1)/2)\n",
    "            stop = int(site.Position) + ((interval-1)/2)\n",
    "            AGrna = eval(site.Bases)[2]/sum(eval(site.Bases))\n",
    "            srr_interval = []\n",
    "            for s in srr.fetch(site.Region, start-1, stop):\n",
    "                srr_interval.append(s.split(\"\\t\"))\n",
    "            srr_interval = pd.DataFrame(srr_interval, columns=columns)\n",
    "            if srr_interval.shape[0] == interval and len(set(srr_interval[\"Strand\"])) == 1:\n",
    "                intervals.append([site.Region, site.Position, site.Ref, site.Strand, AGrna, site.Bases, start, stop, stop-start + 1, srr_interval.shape[0]])\n",
    "                total_extracted += 1\n",
    "                strand = site.Strand\n",
    "                seq = srr_interval.Ref.values.reshape(-1,1)\n",
    "                seq_ohe = ohe.transform(seq).toarray().T\n",
    "                vects_freqs = []\n",
    "                strands = []\n",
    "                vects = []\n",
    "                for vect in srr_interval[\"Bases\"]:\n",
    "                    vect = np.array(eval(vect))\n",
    "                    cov = sum(vect)\n",
    "                    vect_freqs = vect / cov\n",
    "                    vects_freqs.append(vect_freqs)\n",
    "                    vects.append(vect)\n",
    "                vects_freqs = np.array(vects_freqs).T\n",
    "                vects = np.array(vects).T\n",
    "                encoded_site = pd.concat([pd.DataFrame(seq_ohe), pd.DataFrame(vects_freqs)])\n",
    "                encoded_site.reset_index(drop=True, inplace=True)\n",
    "                if strand == 0: \n",
    "                    encoded_site = pd.DataFrame(np.flip(encoded_site.values, axis=1))\n",
    "                encoded_site.to_csv(features_extracted, mode=\"a\", sep=\"\\t\", header = None, index=None)\n",
    "            pbar.update(1)\n",
    "    intervals = pd.DataFrame(intervals)\n",
    "    print(f\"[{datetime.now()}] Total extracted Editing sites: {total_extracted}.\")\n",
    "    stop_time_global = datetime.now()\n",
    "    print(f\"[{datetime.now()}] Features Extraction Finished. Elapsed time {datetime.now()-starttime_preds}.\")\n",
    "    features_extracted.close()\n",
    "    \n",
    "    intervals.columns = [\"Region\", \"Position\", \"RefBase\", \"Strand\", \"FreqAGrna\", \"BasesCounts\", \"Start\", \"Stop\", \"Intlen\", \"TabixLen\"]\n",
    "    intervals.to_csv(prefix + \"_intervals.tsv\", sep=\"\\t\", index=None)\n",
    "    print(f\"[{datetime.now()}] Computation Finished. Total Elapsed time: {datetime.now()-starttime}\")\n",
    "\n",
    "def candidates_bona_fide_extraction(name, path, cells, AG_min, AGfreq_threshold, cov_threshold, rna_cov_threshold, gen):    \n",
    "\n",
    "    starttime = datetime.now()\n",
    "    sites = []\n",
    "    \n",
    "    wgs = pysam.TabixFile(f\"{path}/{cells}_WGS.gz\")                                                                  \n",
    "    with gzip.open(f\"{path}/{name}.gz\") as redi:\n",
    "        for c,l in enumerate(redi):\n",
    "            line = l.decode(\"utf-8\").rstrip().split(\"\\t\")\n",
    "            if line[0].find(\"chr\") != -1:\n",
    "                if line[0] != \"chrM\":\n",
    "                    if line[4] != \"-\":\n",
    "                        if int(line[4]) >= rna_cov_threshold:\n",
    "                            if line[2] == \"A\":\n",
    "                                if \"AG\" in line[7] == \"AG\":    \n",
    "                                    AG_rna = eval(line[6])[2]/sum(eval(line[6]))\n",
    "                                    if AG_rna >= AGfreq_threshold:\n",
    "                                        if eval(line[6])[2] >= AG_min:\n",
    "                                            region = line[0]\n",
    "                                            start = int(line[1])-1\n",
    "                                            stop = int(line[1])\n",
    "                                            for ROW_WGS in wgs.fetch(region, start, stop):\n",
    "                                                row_wgs = ROW_WGS.split(\"\\t\")\n",
    "                                                if row_wgs[9] !=  \"-\":\n",
    "                                                    if int(row_wgs[9])>=cov_threshold:\n",
    "                                                        if \"AG\" in row_wgs[12]:\n",
    "                                                            sites.append([line[0], line[1], 0])\n",
    "                                                        else:\n",
    "                                                            if row_wgs[12] == \"-\":\n",
    "                                                                if line[7] == \"AG\":\n",
    "                                                                    sites.append([line[0], line[1], 1]) \n",
    "                                else:\n",
    "                                    if  line[7] == \"-\":\n",
    "                                        if gen != \"wt\" and gen != \"oe\":                                        \n",
    "                                            sites.append([line[0], line[1], 2])\n",
    "                                                                                           \n",
    "            if c % 50000000 == 0:\n",
    "                print(f\"\\tSites evaluated: {c}\")\n",
    "     \n",
    "    sites = pd.DataFrame(sites)\n",
    "    sites.columns = [\"Region\", \"Position\", \"Class\"]\n",
    "    print(\"Total evaluated rows:\", c)\n",
    "    print(f\"Total extracted candidates bona fide Sites for {name} sample: {sites.shape[0]}\")\n",
    "    stoptime = datetime.now()\n",
    "    \n",
    "    print(f\"[{datetime.now()}] Extraction of candidates bonafide sites finished for {name} sample. Elapsed time: {stoptime-starttime}.\")\n",
    "    sites.to_csv(f\"{path}/{name}_bona_fide_sites.tsv\", sep=\"\\t\", index=None)\n",
    "                                                                                 \n",
    "def bonafide_identification(tables, path, rmsk, refseq):\n",
    "                           \n",
    "    u_path = \"/lustrehome/pietrolucamazzacuva/filezilla-recas/scripts/utilities\"                                                                            \n",
    "                                                                                 \n",
    "    if cells != \"HEK293T\":\n",
    "        for i in range(3):\n",
    "                bonafide_wt = pd.read_table(f\"{path}/{tables[i][0]}_bona_fide_sites.tsv\")\n",
    "                bonafide_adar_inactive = pd.read_table(f\"{path}/{tables[i][1]}_bona_fide_sites.tsv\")\n",
    "                bonafide_adar_inactive = bonafide_adar_inactive[bonafide_adar_inactive.loc[:, \"Class\"]!=2]\n",
    "                bonafide = pd.concat([bonafide_wt, bonafide_adar_inactive], axis=0)\n",
    "                bonafide.drop_duplicates(subset=[\"Region\", \"Position\", \"Class\"], keep=\"first\", inplace=True)\n",
    "                bonafide.to_csv(f\"{path}/{tables[i][0]}_{tables[i][1]}_candidates_bona_fide_sites.tsv\", sep=\"\\t\", index=None, header=False)\n",
    "                \n",
    "    else:\n",
    "        for i in range(3):\n",
    "            for j in [0, 2]:\n",
    "                bonafide_wt = pd.read_table(f\"{path}/{tables[i][j]}_bona_fide_sites.tsv\")\n",
    "                bonafide_adar_inactive = pd.read_table(f\"{path}/{tables[i][1]}_bona_fide_sites.tsv\")\n",
    "                bonafide_adar_inactive = bonafide_adar_inactive[bonafide_adar_inactive.loc[:, \"Class\"]!=2]\n",
    "                bonafide = pd.concat([bonafide_wt, bonafide_adar_inactive], axis=0)\n",
    "                bonafide.drop_duplicates(subset=[\"Region\", \"Position\", \"Class\"], keep=\"first\", inplace=True)\n",
    "                bonafide.to_csv(f\"{path}/{tables[i][j]}_{tables[i][1]}_candidates_bona_fide_sites.tsv\", sep=\"\\t\", index=None, header=False)\n",
    "\n",
    "    for file_name in os.listdir(path):\n",
    "        if file_name.find(\"_candidates_bona_fide_sites.tsv\") !=-1:\n",
    "            df = pd.read_csv(os.path.join(path, file_name), sep=\"\\t\")\n",
    "            df.to_csv(os.path.join(path, file_name), sep=\"\\t\", index=None, header=False)\n",
    "            name = file_name.replace(\".tsv\", \"\")\n",
    "            cmd_sh = \"python3 {}/AnnotateTablePython3.py -a {}/{} -n rmsk -i {}/{}.tsv -o {}/{}.out.rmsk -u\".format(u_path, u_path, rmsk, path, name, path, name)\n",
    "            args = shlex.split(cmd_sh)\n",
    "            p = subprocess.Popen(args, env=dict(os.environ, PATH=\"/lustrehome/pietrolucamazzacuva/anaconda3/envs/tensorflow-gpu/bin\"))\n",
    "\n",
    "    time.sleep(60)\n",
    "\n",
    "    for name in os.listdir(path):\n",
    "        if name.find(\"rmsk\") != -1:\n",
    "            cmd_sh = \"python3 {}/AnnotateTablePython3.py -a {}/{} -i {}/{} -o {}/{}.refseq -u\".format(u_path, u_path, refseq, path, name, path, name)\n",
    "            args = shlex.split(cmd_sh)\n",
    "            p = subprocess.Popen(args, env=dict(os.environ, PATH=\"/lustrehome/pietrolucamazzacuva/anaconda3/envs/tensorflow-gpu/bin\"))\n",
    "\n",
    "    time.sleep(60)\n",
    "\n",
    "    cols = [\"Region\", \"Position\", \"Class\", \"RMSK-Rep\", \"RMSK-Reg\", \"RefSeq-Rep\", \"RefSeq-Reg\"]\n",
    "    for file_name in os.listdir(path):\n",
    "        if file_name.find(\".refseq\") !=-1:\n",
    "            df = pd.read_table(os.path.join(path, file_name), header=None)\n",
    "            name = file_name.replace(\".out.rmsk.refseq\", \"_annoted.tsv\")\n",
    "            df.columns = cols\n",
    "            df.to_csv(os.path.join(path, name), sep=\"\\t\", index=None)\n",
    "\n",
    "    for file_name in os.listdir(path):\n",
    "        if file_name.find(\"candidates_bona_fide_sites_annoted.tsv\") !=-1:\n",
    "            bona_fide = pd.read_csv(os.path.join(path, file_name), sep=\"\\t\")\n",
    "            rep = bona_fide[(bona_fide.iloc[:, 3] != \"-\") & (bona_fide.iloc[:, 4] != \"-\")]\n",
    "            non_rep = bona_fide[(bona_fide.iloc[:, 3] == \"-\") & (bona_fide.iloc[:, 4] == \"-\")]\n",
    "\n",
    "            del bona_fide\n",
    "\n",
    "            non_rep_n = non_rep[non_rep.iloc[:, 2]==0]\n",
    "            non_rep_p = non_rep[non_rep.iloc[:, 2]==1]\n",
    "\n",
    "            del non_rep\n",
    "\n",
    "            non_rep_p = non_rep_p[(non_rep_p.iloc[:, 5] != \"-\") & (non_rep_p.iloc[:, 6] != \"-\")]\n",
    "            bona_fide = pd.concat([rep, non_rep_n, non_rep_p])\n",
    "\n",
    "            del rep, non_rep_n, non_rep_p\n",
    "\n",
    "            name = file_name.replace(\"candidates_bona_fide_sites_annoted.tsv\", \"bona_fide_sites.tsv\")\n",
    "            bona_fide = bona_fide.sort_values([\"Region\", \"Position\"])\n",
    "            bona_fide.to_csv(os.path.join(path, name), sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf05b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\tSites evaluated: 0\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\n",
      "\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "Total evaluated rows: 216398797\n",
      "Total extracted Candidates Editing sites for current sample: 6334\n",
      "[2024-06-20 22:58:22.589626] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:48.816179.\n",
      "[2024-06-20 22:58:22.591373] Starting extraction of intervals.\n",
      "[2024-06-20 22:58:22.602351] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_436061877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/6332 [00:00<00:30, 208.73it/s][W::hts_idx_load3] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_436061877.gz.tbi\n",
      "100%|██████████| 6332/6332 [00:20<00:00, 308.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:58:43.237277] Total extracted Editing sites: 2686.\n",
      "[2024-06-20 22:58:43.238624] Features Extraction Finished. Elapsed time 0:00:20.645196.\n",
      "[2024-06-20 22:58:43.255616] Computation Finished. Total Elapsed time: 0:07:09.482184\n",
      "Total evaluated rows: 236217106\n",
      "Total extracted Candidates Editing sites for current sample: 15176\n",
      "[2024-06-20 22:58:59.608335] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:07:25.834205.\n",
      "[2024-06-20 22:58:59.610056] Starting extraction of intervals.\n",
      "[2024-06-20 22:58:59.621243] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_773331943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 35/15175 [00:00<00:43, 347.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 235536788\n",
      "Total extracted Candidates Editing sites for current sample: 16327\n",
      "[2024-06-20 22:58:59.871058] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:07:26.097302.\n",
      "[2024-06-20 22:58:59.872960] Starting extraction of intervals.\n",
      "[2024-06-20 22:58:59.884580] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_535670354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::hts_idx_load3] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_773331943.gz.tbi\n",
      "  1%|          | 102/15175 [00:00<00:48, 309.59it/s][W::hts_idx_load3] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_535670354.gz.tbi\n",
      " 14%|█▍        | 2266/16326 [00:07<00:44, 318.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 241233789\n",
      "Total extracted Candidates Editing sites for current sample: 8834\n",
      "[2024-06-20 22:59:07.549251] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:07:33.774983.\n",
      "[2024-06-20 22:59:07.551001] Starting extraction of intervals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 2222/15175 [00:07<00:41, 312.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:59:07.560305] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_302610513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2991/16326 [00:09<00:42, 310.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 239780038\n",
      "Total extracted Candidates Editing sites for current sample: 8358\n",
      "[2024-06-20 22:59:09.839079] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:07:36.065105.\n",
      "[2024-06-20 22:59:09.840637] Starting extraction of intervals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 655/8833 [00:02<00:26, 304.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:59:09.848980] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_396704193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1900/8833 [00:06<00:23, 297.19it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 241316303\n",
      "Total extracted Candidates Editing sites for current sample: 18396\n",
      "[2024-06-20 22:59:13.938996] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:07:40.165606.\n",
      "[2024-06-20 22:59:13.940744] Starting extraction of intervals.\n",
      "[2024-06-20 22:59:13.953993] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_192318299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8833/8833 [00:26<00:00, 327.56it/s]]]\n",
      " 98%|█████████▊| 8205/8357 [00:24<00:00, 310.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:59:34.602669] Total extracted Editing sites: 3767.\n",
      "[2024-06-20 22:59:34.604190] Features Extraction Finished. Elapsed time 0:00:27.050903.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 11020/15175 [00:34<00:12, 345.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:59:34.632821] Computation Finished. Total Elapsed time: 0:08:00.858571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8357/8357 [00:25<00:00, 331.66it/s]s]\n",
      " 36%|███▋      | 6688/18396 [00:21<00:29, 390.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:59:35.110966] Total extracted Editing sites: 3526.\n",
      "[2024-06-20 22:59:35.112383] Features Extraction Finished. Elapsed time 0:00:25.269999.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 11359/16326 [00:35<00:14, 338.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:59:35.132154] Computation Finished. Total Elapsed time: 0:08:01.358206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15175/15175 [00:47<00:00, 320.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:59:47.070485] Total extracted Editing sites: 6450.\n",
      "[2024-06-20 22:59:47.072034] Features Extraction Finished. Elapsed time 0:00:47.460085.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 15455/16326 [00:47<00:02, 348.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:59:47.106644] Computation Finished. Total Elapsed time: 0:08:13.332540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16326/16326 [00:49<00:00, 328.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 22:59:49.782611] Total extracted Editing sites: 6856.\n",
      "[2024-06-20 22:59:49.784150] Features Extraction Finished. Elapsed time 0:00:49.909293.\n",
      "[2024-06-20 22:59:49.823810] Computation Finished. Total Elapsed time: 0:08:16.050076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18396/18396 [00:56<00:00, 327.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:00:10.258783] Total extracted Editing sites: 7691.\n",
      "[2024-06-20 23:00:10.260284] Features Extraction Finished. Elapsed time 0:00:56.317654.\n",
      "[2024-06-20 23:00:10.299339] Computation Finished. Total Elapsed time: 0:08:36.525977\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "Total evaluated rows: 216398797\n",
      "Total extracted candidates bona fide Sites for outTable_436061877 sample: 5913752\n",
      "[2024-06-20 23:07:47.008350] Extraction of candidates bonafide sites finished for outTable_436061877 sample. Elapsed time: 0:07:36.533424.\n",
      "Total evaluated rows: 236217106\n",
      "Total extracted candidates bona fide Sites for outTable_773331943 sample: 13224\n",
      "[2024-06-20 23:08:20.815210] Extraction of candidates bonafide sites finished for outTable_773331943 sample. Elapsed time: 0:08:10.339917.\n",
      "Total evaluated rows: 235536788\n",
      "Total extracted candidates bona fide Sites for outTable_535670354 sample: 14181\n",
      "[2024-06-20 23:08:22.148181] Extraction of candidates bonafide sites finished for outTable_535670354 sample. Elapsed time: 0:08:11.673157.\n",
      "Total evaluated rows: 239780038\n",
      "Total extracted candidates bona fide Sites for outTable_396704193 sample: 6815925\n",
      "[2024-06-20 23:08:30.893364] Extraction of candidates bonafide sites finished for outTable_396704193 sample. Elapsed time: 0:08:20.418217.\n",
      "Total evaluated rows: 241233789\n",
      "Total extracted candidates bona fide Sites for outTable_302610513 sample: 7002637\n",
      "[2024-06-20 23:08:30.931368] Extraction of candidates bonafide sites finished for outTable_302610513 sample. Elapsed time: 0:08:20.455968.\n",
      "Total evaluated rows: 241316303\n",
      "Total extracted candidates bona fide Sites for outTable_192318299 sample: 15764\n",
      "[2024-06-20 23:08:38.457571] Extraction of candidates bonafide sites finished for outTable_192318299 sample. Elapsed time: 0:08:27.982772.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:08:45\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_192318299_outTable_436061877_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 20/06/2024 23:08:50\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:08:45\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_535670354_outTable_396704193_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 20/06/2024 23:08:50\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:08:45\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_773331943_outTable_302610513_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 20/06/2024 23:08:50\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:09:43\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_535670354_outTable_396704193_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 20/06/2024 23:09:47\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:09:43\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_773331943_outTable_302610513_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 20/06/2024 23:09:47\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:09:43\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_192318299_outTable_436061877_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 20/06/2024 23:09:47\n"
     ]
    }
   ],
   "source": [
    "min_dna_cov = 10\n",
    "min_rna_cov = 50\n",
    "min_AG_rate = 0.01\n",
    "min_G = 3\n",
    "seq_lenght = 101\n",
    "\n",
    "cells = \"a549\"\n",
    "\n",
    "samples, rmsk_file_name, refseq_file_name, filespath = give_inputs(cells)\n",
    "    \n",
    "inputs = []\n",
    "for i in range(len(samples)):\n",
    "    for j in range(len(samples[i])):\n",
    "        inputs.append([os.path.join(filespath, f\"{samples[i][j]}\"), min_G, min_AG_rate, min_rna_cov, seq_lenght])\n",
    "\n",
    "with Pool(9) as pool:\n",
    "    pool.starmap(extraction, inputs)\n",
    "\n",
    "inputs = []\n",
    "for i in range(3):\n",
    "    inputs.append([samples[i][0], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov, \"wt\"])\n",
    "    inputs.append([samples[i][1], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov, \"si\"])\n",
    "    \n",
    "with Pool(6) as pool:\n",
    "    pool.starmap(candidates_bona_fide_extraction, inputs)     \n",
    "\n",
    "bonafide_identification(samples, filespath, rmsk_file_name, refseq_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74083200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 0\tSites evaluated: 0\n",
      "\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\tSites evaluated: 0\n",
      "\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "Total evaluated rows: 194677901\n",
      "Total extracted Candidates Editing sites for current sample: 11705\n",
      "[2024-06-20 23:16:49.662308] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:06.126549.\n",
      "[2024-06-20 23:16:49.663888] Starting extraction of intervals.\n",
      "[2024-06-20 23:16:49.683152] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_905657585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 2299/11701 [00:07<00:28, 333.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 199831579\n",
      "Total extracted Candidates Editing sites for current sample: 24397\n",
      "[2024-06-20 23:16:57.528219] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:13.991545.\n",
      "[2024-06-20 23:16:57.529895] Starting extraction of intervals.\n",
      "[2024-06-20 23:16:57.547187] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_110067244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 2502/11701 [00:08<00:28, 325.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 175/24391 [00:00<01:32, 260.54it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 3287/11701 [00:10<00:25, 336.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1463/24391 [00:04<01:05, 352.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4032/11701 [00:13<00:20, 375.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1989/24391 [00:06<01:10, 317.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 5201/11701 [00:16<00:19, 330.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 3537/24391 [00:11<01:01, 338.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 205675117\n",
      "Total extracted Candidates Editing sites for current sample: 11897\n",
      "[2024-06-20 23:17:08.904752] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:25.368399.\n",
      "[2024-06-20 23:17:08.906031] Starting extraction of intervals.\n",
      "[2024-06-20 23:17:08.916164] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_364841872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 1949/11891 [00:05<00:27, 362.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 208788107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 8145/11701 [00:25<00:09, 372.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extracted Candidates Editing sites for current sample: 11086\n",
      "[2024-06-20 23:17:14.842036] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:31.305257.\n",
      "[2024-06-20 23:17:14.843638] Starting extraction of intervals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 5568/24391 [00:16<00:53, 353.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:17:14.854045] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_597789462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11701/11701 [00:35<00:00, 330.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:17:25.121305] Total extracted Editing sites: 5094.\n",
      "[2024-06-20 23:17:25.122692] Features Extraction Finished. Elapsed time 0:00:35.456901.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 8909/24391 [00:27<00:46, 334.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:17:25.150804] Computation Finished. Total Elapsed time: 0:06:41.615066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11891/11891 [00:37<00:00, 318.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:17:46.416743] Total extracted Editing sites: 5077.\n",
      "[2024-06-20 23:17:46.418239] Features Extraction Finished. Elapsed time 0:00:37.510433.\n",
      "[2024-06-20 23:17:46.448269] Computation Finished. Total Elapsed time: 0:07:02.911940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11079/11079 [00:32<00:00, 339.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:17:47.666364] Total extracted Editing sites: 4770.\n",
      "[2024-06-20 23:17:47.667852] Features Extraction Finished. Elapsed time 0:00:32.822303.\n",
      "[2024-06-20 23:17:47.693392] Computation Finished. Total Elapsed time: 0:07:04.156634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24391/24391 [01:13<00:00, 332.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:18:11.325984] Total extracted Editing sites: 9960.\n",
      "[2024-06-20 23:18:11.327608] Features Extraction Finished. Elapsed time 0:01:13.795830.\n",
      "[2024-06-20 23:18:11.378308] Computation Finished. Total Elapsed time: 0:07:27.841671\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "Total evaluated rows: 266283468\n",
      "Total extracted Candidates Editing sites for current sample: 54617\n",
      "[2024-06-20 23:19:09.523138] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:08:25.987219.\n",
      "[2024-06-20 23:19:09.524678] Starting extraction of intervals.\n",
      "[2024-06-20 23:19:09.553983] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_208420383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 12036/54614 [00:38<02:08, 330.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 288775068\n",
      "Total extracted Candidates Editing sites for current sample: 37723\n",
      "[2024-06-20 23:19:48.632268] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:09:05.096241.\n",
      "[2024-06-20 23:19:48.634055] Starting extraction of intervals.\n",
      "[2024-06-20 23:19:48.656887] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_572868058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 5509/37720 [00:18<01:49, 293.84it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 298198400\n",
      "Total extracted Candidates Editing sites for current sample: 67410\n",
      "[2024-06-20 23:20:07.617086] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:09:24.080233.\n",
      "[2024-06-20 23:20:07.618757] Starting extraction of intervals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 17880/54614 [00:57<01:53, 322.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:20:07.651913] Loading reditable with tabix and pysam:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 5539/37720 [00:18<01:49, 294.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_530905096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 46/67408 [00:00<02:27, 456.46it/s]/s][W::hts_idx_load3] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_530905096.gz.tbi\n",
      " 34%|███▍      | 18580/54614 [01:00<02:37, 228.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 298335470\n",
      "Total extracted Candidates Editing sites for current sample: 66236\n",
      "[2024-06-20 23:20:10.089100] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:09:26.552563.\n",
      "[2024-06-20 23:20:10.090511] Starting extraction of intervals."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 6225/37720 [00:21<01:49, 288.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2024-06-20 23:20:10.125660] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_814257267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45/66233 [00:00<02:28, 444.92it/s]s]][W::hts_idx_load3] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_814257267.gz.tbi\n",
      "  3%|▎         | 1682/66233 [00:07<02:58, 362.31it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 300000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37720/37720 [02:03<00:00, 304.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:21:52.545699] Total extracted Editing sites: 15241.\n",
      "[2024-06-20 23:21:52.547589] Features Extraction Finished. Elapsed time 0:02:03.911378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 30356/66233 [01:42<02:21, 253.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:21:52.619219] Computation Finished. Total Elapsed time: 0:11:09.083227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 30561/66233 [01:42<01:48, 329.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 350000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54614/54614 [02:56<00:00, 310.28it/s]\n",
      " 52%|█████▏    | 34423/66233 [01:55<01:47, 296.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:22:05.709157] Total extracted Editing sites: 22910.\n",
      "[2024-06-20 23:22:05.711114] Features Extraction Finished. Elapsed time 0:02:56.184547.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 34453/66233 [01:55<01:47, 295.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:22:05.819946] Computation Finished. Total Elapsed time: 0:11:22.284066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 42068/66233 [02:20<01:15, 320.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 369524874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 42794/67408 [02:22<01:28, 279.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extracted Candidates Editing sites for current sample: 54971\n",
      "[2024-06-20 23:22:30.445528] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:11:46.909936.\n",
      "[2024-06-20 23:22:30.447296] Starting extraction of intervals.\n",
      "[2024-06-20 23:22:30.476711] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_599710609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66233/66233 [03:38<00:00, 302.96it/s]\n",
      " 99%|█████████▉| 66777/67408 [03:41<00:01, 355.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:23:48.894535] Total extracted Editing sites: 27907.\n",
      "[2024-06-20 23:23:48.896641] Features Extraction Finished. Elapsed time 0:03:38.804193.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 66813/67408 [03:41<00:01, 322.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:23:49.019091] Computation Finished. Total Elapsed time: 0:13:05.482591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67408/67408 [03:43<00:00, 301.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:23:51.105796] Total extracted Editing sites: 28354.\n",
      "[2024-06-20 23:23:51.107770] Features Extraction Finished. Elapsed time 0:03:43.487258.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 22813/54968 [01:20<01:39, 322.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:23:51.235882] Computation Finished. Total Elapsed time: 0:13:07.699063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54968/54968 [03:10<00:00, 288.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 23:25:41.172069] Total extracted Editing sites: 22284.\n",
      "[2024-06-20 23:25:41.173951] Features Extraction Finished. Elapsed time 0:03:10.724731.\n",
      "[2024-06-20 23:25:41.274966] Computation Finished. Total Elapsed time: 0:14:57.739403\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "Total evaluated rows: 194677901\n",
      "Total extracted candidates bona fide Sites for outTable_905657585 sample: 8210567\n",
      "[2024-06-20 23:32:33.835527] Extraction of candidates bonafide sites finished for outTable_905657585 sample. Elapsed time: 0:06:52.343465.\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 0\n",
      "Total evaluated rows: 205675117\n",
      "Total extracted candidates bona fide Sites for outTable_364841872 sample: 8434410\n",
      "[2024-06-20 23:32:53.644553] Extraction of candidates bonafide sites finished for outTable_364841872 sample. Elapsed time: 0:07:12.152096.\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "Total evaluated rows: 266283468\n",
      "Total extracted candidates bona fide Sites for outTable_208420383 sample: 54266\n",
      "[2024-06-20 23:36:01.070954] Extraction of candidates bonafide sites finished for outTable_208420383 sample. Elapsed time: 0:10:19.578806.\n",
      "\tSites evaluated: 0\n",
      "Total evaluated rows: 288775068\n",
      "Total extracted candidates bona fide Sites for outTable_572868058 sample: 37502\n",
      "[2024-06-20 23:36:12.221671] Extraction of candidates bonafide sites finished for outTable_572868058 sample. Elapsed time: 0:10:30.729383.\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 300000000\n",
      "Total evaluated rows: 298335470\n",
      "Total extracted candidates bona fide Sites for outTable_814257267 sample: 65814\n",
      "[2024-06-20 23:37:25.742637] Extraction of candidates bonafide sites finished for outTable_814257267 sample. Elapsed time: 0:11:44.250046.\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 350000000\n",
      "Total evaluated rows: 369524874\n",
      "Total extracted candidates bona fide Sites for outTable_599710609 sample: 54579\n",
      "[2024-06-20 23:39:21.635373] Extraction of candidates bonafide sites finished for outTable_599710609 sample. Elapsed time: 0:13:40.143450.\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 100000000\n",
      "Total evaluated rows: 199831579\n",
      "Total extracted candidates bona fide Sites for outTable_110067244 sample: 24278\n",
      "[2024-06-20 23:40:02.771741] Extraction of candidates bonafide sites finished for outTable_110067244 sample. Elapsed time: 0:07:19.878163.\n",
      "Total evaluated rows: 208788107\n",
      "Total extracted candidates bona fide Sites for outTable_597789462 sample: 8387652\n",
      "[2024-06-20 23:40:15.746702] Extraction of candidates bonafide sites finished for outTable_597789462 sample. Elapsed time: 0:07:12.808893.\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 250000000\n",
      "Total evaluated rows: 298198400\n",
      "Total extracted candidates bona fide Sites for outTable_530905096 sample: 66987\n",
      "[2024-06-20 23:47:54.580183] Extraction of candidates bonafide sites finished for outTable_530905096 sample. Elapsed time: 0:11:53.443238.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:48:06\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_110067244_outTable_597789462_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 20/06/2024 23:48:14\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:48:06\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_572868058_outTable_364841872_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 20/06/2024 23:48:15\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:48:06\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_208420383_outTable_905657585_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 20/06/2024 23:48:17\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:48:06\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_599710609_outTable_905657585_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 20/06/2024 23:48:17\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:48:06\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_814257267_outTable_364841872_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 20/06/2024 23:48:18\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:48:06\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_530905096_outTable_597789462_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 20/06/2024 23:48:18\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:49:05\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_110067244_outTable_597789462_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 20/06/2024 23:49:18\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:49:05\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_572868058_outTable_364841872_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 20/06/2024 23:49:20\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:49:05\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_599710609_outTable_905657585_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 20/06/2024 23:49:23\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:49:05\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_208420383_outTable_905657585_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 20/06/2024 23:49:24\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:49:05\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_814257267_outTable_364841872_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 20/06/2024 23:49:26\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 20/06/2024 23:49:05\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_530905096_outTable_597789462_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 20/06/2024 23:49:26\n"
     ]
    }
   ],
   "source": [
    "min_dna_cov = 10\n",
    "min_rna_cov = 50\n",
    "min_AG_rate = 0.01\n",
    "min_G = 3\n",
    "seq_lenght = 101\n",
    "\n",
    "cells = \"HEK293T\"\n",
    "\n",
    "samples, rmsk_file_name, refseq_file_name, filespath = give_inputs(cells)\n",
    "    \n",
    "inputs = []\n",
    "for i in range(len(samples)):\n",
    "    for j in range(len(samples[i])):\n",
    "        inputs.append([os.path.join(filespath, f\"{samples[i][j]}\"), min_G, min_AG_rate, min_rna_cov, seq_lenght])\n",
    "\n",
    "with Pool(9) as pool:\n",
    "    pool.starmap(extraction, inputs)\n",
    "\n",
    "inputs = []\n",
    "for i in range(3):\n",
    "    inputs.append([samples[i][0], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov, \"wt\"])\n",
    "    inputs.append([samples[i][1], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov, \"ko\"])\n",
    "    inputs.append([samples[i][2], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov, \"oe\"])\n",
    "    \n",
    "with Pool(6) as pool:\n",
    "    pool.starmap(candidates_bona_fide_extraction, inputs)     \n",
    "\n",
    "bonafide_identification(samples, filespath, rmsk_file_name, refseq_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac79015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "Total evaluated rows: 419443529\n",
      "Total extracted Candidates Editing sites for current sample: 4989\n",
      "[2024-06-21 00:02:53.886714] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:12:46.010331.\n",
      "[2024-06-21 00:02:53.888388] Starting extraction of intervals.\n",
      "[2024-06-21 00:02:53.915656] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_718392497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1340/4980 [00:15<00:28, 125.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 422584480\n",
      "Total extracted Candidates Editing sites for current sample: 12583\n",
      "[2024-06-21 00:03:09.575480] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:13:01.698895.\n",
      "[2024-06-21 00:03:09.577170] Starting extraction of intervals.\n",
      "[2024-06-21 00:03:09.593031] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_181728208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4980/4980 [00:35<00:00, 139.97it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-21 00:03:29.619463] Total extracted Editing sites: 2111.\n",
      "[2024-06-21 00:03:29.620904] Features Extraction Finished. Elapsed time 0:00:35.730531.\n",
      "[2024-06-21 00:03:29.634804] Computation Finished. Total Elapsed time: 0:13:21.758437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 10215/12571 [00:39<00:08, 288.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 450000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12571/12571 [00:47<00:00, 262.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-21 00:03:57.681722] Total extracted Editing sites: 5419.\n",
      "[2024-06-21 00:03:57.683067] Features Extraction Finished. Elapsed time 0:00:48.103907.\n",
      "[2024-06-21 00:03:57.710897] Computation Finished. Total Elapsed time: 0:13:49.834337\n",
      "\tSites evaluated: 450000000\n",
      "\tSites evaluated: 450000000\n",
      "Total evaluated rows: 452378572\n",
      "Total extracted Candidates Editing sites for current sample: 8304\n",
      "[2024-06-21 00:04:08.446169] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:14:00.570265.\n",
      "[2024-06-21 00:04:08.447757] Starting extraction of intervals.\n",
      "[2024-06-21 00:04:08.456748] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_724242056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 317/8295 [00:03<01:29, 88.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 450000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 6697/8295 [00:39<00:04, 351.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 469580145\n",
      "Total extracted Candidates Editing sites for current sample: 6281\n",
      "[2024-06-21 00:04:48.147142] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:14:40.271069.\n",
      "[2024-06-21 00:04:48.148722] Starting extraction of intervals.\n",
      "[2024-06-21 00:04:48.156728] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_816573740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 7717/8295 [00:43<00:02, 262.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 483808594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 483/6270 [00:03<00:23, 245.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extracted Candidates Editing sites for current sample: 12185\n",
      "[2024-06-21 00:04:51.760578] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:14:43.884334.\n",
      "[2024-06-21 00:04:51.762162] Starting extraction of intervals.\n",
      "[2024-06-21 00:04:51.771791] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_580067564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8295/8295 [00:45<00:00, 181.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-21 00:04:54.297978] Total extracted Editing sites: 3457.\n",
      "[2024-06-21 00:04:54.299496] Features Extraction Finished. Elapsed time 0:00:45.849778.\n",
      "[2024-06-21 00:04:54.319516] Computation Finished. Total Elapsed time: 0:14:46.443629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6270/6270 [00:34<00:00, 179.16it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-21 00:05:23.239732] Total extracted Editing sites: 2710.\n",
      "[2024-06-21 00:05:23.241228] Features Extraction Finished. Elapsed time 0:00:35.090540.\n",
      "[2024-06-21 00:05:23.257438] Computation Finished. Total Elapsed time: 0:15:15.381380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 10329/12180 [00:46<00:10, 180.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 500000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12180/12180 [00:56<00:00, 216.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-21 00:05:48.038639] Total extracted Editing sites: 5312.\n",
      "[2024-06-21 00:05:48.040024] Features Extraction Finished. Elapsed time 0:00:56.275927.\n",
      "[2024-06-21 00:05:48.068157] Computation Finished. Total Elapsed time: 0:15:40.191933\n",
      "Total evaluated rows: 519011879\n",
      "Total extracted Candidates Editing sites for current sample: 7987\n",
      "[2024-06-21 00:06:14.468222] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:16:06.591532.\n",
      "[2024-06-21 00:06:14.469949] Starting extraction of intervals.\n",
      "[2024-06-21 00:06:14.478656] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_854894021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7971/7971 [00:46<00:00, 173.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-21 00:07:00.883094] Total extracted Editing sites: 3620.\n",
      "[2024-06-21 00:07:00.884411] Features Extraction Finished. Elapsed time 0:00:46.412478.\n",
      "[2024-06-21 00:07:00.903324] Computation Finished. Total Elapsed time: 0:16:53.026649\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "Total evaluated rows: 419443529\n",
      "Total extracted candidates bona fide Sites for outTable_718392497 sample: 6588373\n",
      "[2024-06-21 00:20:57.437563] Extraction of candidates bonafide sites finished for outTable_718392497 sample. Elapsed time: 0:13:56.383212.\n",
      "Total evaluated rows: 422584480\n",
      "Total extracted candidates bona fide Sites for outTable_181728208 sample: 12500\n",
      "[2024-06-21 00:21:03.813398] Extraction of candidates bonafide sites finished for outTable_181728208 sample. Elapsed time: 0:14:02.758947.\n",
      "\tSites evaluated: 450000000\n",
      "\tSites evaluated: 450000000\n",
      "\tSites evaluated: 450000000\n",
      "\tSites evaluated: 450000000\n",
      "Total evaluated rows: 452378572\n",
      "Total extracted candidates bona fide Sites for outTable_724242056 sample: 8252\n",
      "[2024-06-21 00:22:02.689491] Extraction of candidates bonafide sites finished for outTable_724242056 sample. Elapsed time: 0:15:01.635750.\n",
      "Total evaluated rows: 469580145\n",
      "Total extracted candidates bona fide Sites for outTable_816573740 sample: 7683845\n",
      "[2024-06-21 00:22:33.212654] Extraction of candidates bonafide sites finished for outTable_816573740 sample. Elapsed time: 0:15:32.158824.\n",
      "Total evaluated rows: 483808594\n",
      "Total extracted candidates bona fide Sites for outTable_580067564 sample: 12120\n",
      "[2024-06-21 00:22:49.170207] Extraction of candidates bonafide sites finished for outTable_580067564 sample. Elapsed time: 0:15:48.116245.\n",
      "\tSites evaluated: 500000000\n",
      "Total evaluated rows: 519011879\n",
      "Total extracted candidates bona fide Sites for outTable_854894021 sample: 9127317\n",
      "[2024-06-21 00:24:11.115768] Extraction of candidates bonafide sites finished for outTable_854894021 sample. Elapsed time: 0:17:10.061247.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 21/06/2024 00:24:28\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_580067564_outTable_718392497_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 21/06/2024 00:24:32\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 21/06/2024 00:24:28\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_724242056_outTable_816573740_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 21/06/2024 00:24:32\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 21/06/2024 00:24:28\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_181728208_outTable_854894021_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 21/06/2024 00:24:33\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 21/06/2024 00:25:26\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_580067564_outTable_718392497_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 21/06/2024 00:25:30\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 21/06/2024 00:25:26\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_724242056_outTable_816573740_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 21/06/2024 00:25:30\n",
      "Pysam version used: 0.22.0\n",
      "Script time --> START: 21/06/2024 00:25:26\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_181728208_outTable_854894021_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 21/06/2024 00:25:30\n"
     ]
    }
   ],
   "source": [
    "min_dna_cov = 10\n",
    "min_rna_cov = 30\n",
    "min_AG_rate = 0.01\n",
    "min_G = 2\n",
    "seq_lenght = 101\n",
    "\n",
    "cells = \"HEK\"\n",
    "\n",
    "samples, rmsk_file_name, refseq_file_name, filespath = give_inputs(cells)\n",
    "    \n",
    "inputs = []\n",
    "for i in range(len(samples)):\n",
    "    for j in range(len(samples[i])):\n",
    "        inputs.append([os.path.join(filespath, f\"{samples[i][j]}\"), min_G, min_AG_rate, min_rna_cov, seq_lenght])\n",
    "\n",
    "with Pool(9) as pool:\n",
    "    pool.starmap(extraction, inputs)\n",
    "    \n",
    "inputs = []\n",
    "for i in range(3):\n",
    "    inputs.append([samples[i][0], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov, \"wt\"])\n",
    "    inputs.append([samples[i][1], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov, \"ko\"])\n",
    "\n",
    "with Pool(6) as pool:\n",
    "    pool.starmap(candidates_bona_fide_extraction, inputs)     \n",
    "\n",
    "bonafide_identification(samples, filespath, rmsk_file_name, refseq_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc3e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

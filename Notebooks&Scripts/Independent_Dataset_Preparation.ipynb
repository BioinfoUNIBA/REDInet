{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64b16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023-2024 Pietro Luca Mazzacuva <pietroluca.mazzacuva@unicampus.it>\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, pysam, gzip, subprocess, shlex, time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def give_inputs(cell_line):\n",
    "    \n",
    "    files_path = \"/lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/{}\".format(cells)\n",
    "    \n",
    "    if cell_line == \"HEK293T\":  \n",
    "        samples = [[\"outTable_599710609\", \"outTable_905657585\", \"outTable_208420383\"],\n",
    "                   [\"outTable_572868058\", \"outTable_364841872\", \"outTable_814257267\"],\n",
    "                   [\"outTable_110067244\", \"outTable_597789462\", \"outTable_530905096\"]]\n",
    "\n",
    "        rmsk_file = \"rmsk_hg38.sorted.gtf.gz\"\n",
    "        refseq_file = \"hg38.110.ncbiRefSeq.sorted.gtf.gz\"\n",
    "\n",
    "    elif cell_line == \"HEK\":\n",
    "        samples = [[\"outTable_724242056\", \"outTable_816573740\"],\n",
    "                   [\"outTable_580067564\", \"outTable_718392497\"],\n",
    "                   [\"outTable_181728208\", \"outTable_854894021\"]]\n",
    "        rmsk_file = \"rmsk.sorted.gtf.gz\"\n",
    "        refseq_file = \"hg19.ncbiRefSeq.sorted.gtf.gz\"\n",
    "\n",
    "    else:\n",
    "        samples = [[\"outTable_192318299\", \"outTable_436061877\"],\n",
    "                   [\"outTable_535670354\", \"outTable_396704193\"],\n",
    "                   [\"outTable_773331943\", \"outTable_302610513\"]]\n",
    "        rmsk_file = \"rmsk.sorted.gtf.gz\"\n",
    "        refseq_file = \"hg19.ncbiRefSeq.sorted.gtf.gz\"\n",
    "    \n",
    "    return samples, rmsk_file, refseq_file, files_path\n",
    "\n",
    "def extraction(prefix,  AG_min, AGfreq_threshold, cov_threshold, interval):    \n",
    "    \n",
    "    starttime = datetime.now()\n",
    "\n",
    "    editing = []\n",
    "                                         \n",
    "    with gzip.open(prefix+\".gz\") as redi:\n",
    "        for c,l in enumerate(redi):\n",
    "            line = l.decode(\"utf-8\").rstrip().split(\"\\t\")\n",
    "            if line[2] == \"A\":\n",
    "                if line[4] != \"-\":\n",
    "                    if int(line[4]) >= cov_threshold:\n",
    "                        if \"AG\" in line[7]:    \n",
    "                            AG_rna = eval(line[6])[2]/sum(eval(line[6]))\n",
    "                            if AG_rna >= AGfreq_threshold:\n",
    "                                if eval(line[6])[2] >= AG_min:\n",
    "                                    editing.append(line)\n",
    "\n",
    "            if c % 50000000 == 0:\n",
    "                print(f\"\\tSites evaluated: {c}\")\n",
    "    print(\"Total evaluated rows:\", c)\n",
    "    editing = pd.DataFrame(editing)\n",
    "    print(\"Total extracted Candidates Editing sites for current sample:\", editing.shape[0])\n",
    "    stoptime = datetime.now()\n",
    "    print(f\"[{datetime.now()}] Extraction of Editing Candidates finished for current sample. Elapsed time: {stoptime-starttime}.\")\n",
    "    columns = [\"Region\", \"Position\", \"Ref\", \"Strand\", \"Cov\", \"Qual\", \"Bases\", \"AllSubs\", \"Freq\", \"gCov\", \"gQual\", \"g[A,C,G,T]\", \"gAllSubs\", \"gFreq\"]\n",
    "    editing.columns = columns\n",
    "    print(f\"[{datetime.now()}] Starting extraction of intervals.\")\n",
    "    ohe = OneHotEncoder()\n",
    "    ohe.fit(np.array([\"A\", \"C\", \"G\", \"T\"]).reshape(-1, 1))\n",
    "\n",
    "    intervals = []\n",
    "    starttime_preds = datetime.now()\n",
    "    total_extracted = 0\n",
    "    features_extracted_filepath = prefix+ \"_feature_vectors.tsv\"\n",
    "    features_extracted = open(features_extracted_filepath, \"w\")\n",
    "\n",
    "    df = editing.query(\"Region != 'chrM'\")\n",
    "    print(f\"[{datetime.now()}] Loading reditable with tabix and pysam:\", prefix)\n",
    "    start_time = datetime.now()\n",
    "    srr = pysam.TabixFile(prefix+\".gz\")\n",
    "    with tqdm(total=df.shape[0], position=0, leave=True) as pbar:\n",
    "        for site in df.itertuples():\n",
    "            start = int(site.Position) - ((interval-1)/2)\n",
    "            stop = int(site.Position) + ((interval-1)/2)\n",
    "            AGrna = eval(site.Bases)[2]/sum(eval(site.Bases))\n",
    "            srr_interval = []\n",
    "            for s in srr.fetch(site.Region, start-1, stop):\n",
    "                srr_interval.append(s.split(\"\\t\"))\n",
    "            srr_interval = pd.DataFrame(srr_interval, columns=columns)\n",
    "            if srr_interval.shape[0] == interval and len(set(srr_interval[\"Strand\"])) == 1:\n",
    "                intervals.append([site.Region, site.Position, site.Ref, site.Strand, AGrna, site.Bases, start, stop, stop-start + 1, srr_interval.shape[0]])\n",
    "                total_extracted += 1\n",
    "                strand = site.Strand\n",
    "                seq = srr_interval.Ref.values.reshape(-1,1)\n",
    "                seq_ohe = ohe.transform(seq).toarray().T\n",
    "                vects_freqs = []\n",
    "                strands = []\n",
    "                vects = []\n",
    "                for vect in srr_interval[\"Bases\"]:\n",
    "                    vect = np.array(eval(vect))\n",
    "                    cov = sum(vect)\n",
    "                    vect_freqs = vect / cov\n",
    "                    vects_freqs.append(vect_freqs)\n",
    "                    vects.append(vect)\n",
    "                vects_freqs = np.array(vects_freqs).T\n",
    "                vects = np.array(vects).T\n",
    "                encoded_site = pd.concat([pd.DataFrame(seq_ohe), pd.DataFrame(vects_freqs)])\n",
    "                encoded_site.reset_index(drop=True, inplace=True)\n",
    "                if strand == 0: \n",
    "                    encoded_site = pd.DataFrame(np.flip(encoded_site.values, axis=1))\n",
    "                encoded_site.to_csv(features_extracted, mode=\"a\", sep=\"\\t\", header = None, index=None)\n",
    "            pbar.update(1)\n",
    "    intervals = pd.DataFrame(intervals)\n",
    "    print(f\"[{datetime.now()}] Total extracted Editing sites: {total_extracted}.\")\n",
    "    stop_time_global = datetime.now()\n",
    "    print(f\"[{datetime.now()}] Features Extraction Finished. Elapsed time {datetime.now()-starttime_preds}.\")\n",
    "    features_extracted.close()\n",
    "    \n",
    "    intervals.columns = [\"Region\", \"Position\", \"RefBase\", \"Strand\", \"FreqAGrna\", \"BasesCounts\", \"Start\", \"Stop\", \"Intlen\", \"TabixLen\"]\n",
    "    intervals.to_csv(prefix + \"_intervals.tsv\", sep=\"\\t\", index=None)\n",
    "    print(f\"[{datetime.now()}] Computation Finished. Total Elapsed time: {datetime.now()-starttime}\")\n",
    "\n",
    "def candidates_bona_fide_extraction(name1, name2, path, cells, AG_min, AGfreq_threshold, cov_threshold, rna_cov_threshold):    \n",
    "\n",
    "    starttime = datetime.now()\n",
    "    sites = []\n",
    "    \n",
    "    wgs = pysam.TabixFile(f\"{path}/{cells}_WGS.gz\")   \n",
    "    inactive = pysam.TabixFile(f\"{path}/{name2}.gz\")\n",
    "    with gzip.open(f\"{path}/{name1}.gz\") as redi:\n",
    "\n",
    "        for c,l in enumerate(redi):\n",
    "            line = l.decode(\"utf-8\").rstrip().split(\"\\t\")\n",
    "            if line[0].find(\"chr\") != -1:\n",
    "                if line[2] == \"A\":\n",
    "                    if line[4] != \"-\":\n",
    "                        if int(line[4]) >= cov_threshold:\n",
    "                            if \"AG\" in line[7]:    \n",
    "                                AG_rna = eval(line[6])[2]/sum(eval(line[6]))\n",
    "                                if AG_rna >= AGfreq_threshold:\n",
    "                                    if eval(line[6])[2] >= AG_min:\n",
    "                                        region = line[0]\n",
    "                                        start = int(line[1])-1\n",
    "                                        stop = int(line[1])\n",
    "                                        for ROW_inactive in inactive.fetch(region, start, stop):\n",
    "                                            row_inactive = ROW_inactive.split(\"\\t\")\n",
    "                                            if row_inactive[4] != \"-\":\n",
    "                                                if int(row_inactive[4]) >= rna_cov_threshold:\n",
    "                                                    sub_inactive = eval(row_inactive[6])[2]\n",
    "                                                    for ROW_WGS in wgs.fetch(region, start, stop):\n",
    "                                                        row_wgs = ROW_WGS.split(\"\\t\")\n",
    "                                                        if row_wgs[9] !=  \"-\":\n",
    "                                                            if int(row_wgs[9])>=cov_threshold:\n",
    "                                                                sub_wgs = eval(row_wgs[11])[2]\n",
    "                                                                if sub_wgs == 0:\n",
    "                                                                    if sub_inactive == 0:\n",
    "                                                                        sites.append([line[0], line[1], 1])\n",
    "                                                                else:\n",
    "                                                                    if sub_inactive >= AG_min:\n",
    "                                                                        sites.append([line[0], line[1], 0])\n",
    "                                                                                                               \n",
    "            if c % 50000000 == 0:\n",
    "                print(f\"\\tSites evaluated: {c}\")\n",
    "     \n",
    "    sites = pd.DataFrame(sites)\n",
    "    sites.columns = [\"Region\", \"Position\", \"Class\"]\n",
    "    positives = sites[sites.loc[:, \"Class\"]==1].shape[0]\n",
    "    negatives = sites[sites.loc[:, \"Class\"]==0].shape[0]\n",
    "    print(\"Total evaluated rows:\", c)\n",
    "    print(f\"Total extracted candidates bona fide Sites for {name1} {name2} samples: {sites.shape[0]}\")\n",
    "    print(f\"Total candidates positives bona fide Sites for {name1} {name2} samples: {positives}\")\n",
    "    print(f\"Total candidates negatives bona fide Sites for {name1} {name2} samples: {negatives}\")\n",
    "    stoptime = datetime.now()\n",
    "    \n",
    "    print(f\"[{datetime.now()}] Extraction of candidates bonafide sites finished for {name1} {name2} samples. Elapsed time: {stoptime-starttime}.\")\n",
    "    sites.to_csv(f\"{path}/{name1}_{name2}_candidates_bona_fide_sites.tsv\", sep=\"\\t\", index=None)\n",
    "                                                                                 \n",
    "def bonafide_identification(path, rmsk, refseq):\n",
    "                           \n",
    "    u_path = \"/lustrehome/pietrolucamazzacuva/filezilla-recas/scripts/utilities\"                                                                            \n",
    "                                                                                 \n",
    "    for file_name in os.listdir(path):\n",
    "        if file_name.find(\"_candidates_bona_fide_sites.tsv\") !=-1:\n",
    "            df = pd.read_csv(os.path.join(path, file_name), sep=\"\\t\")\n",
    "            df.to_csv(os.path.join(path, file_name), sep=\"\\t\", index=None, header=False)\n",
    "            name = file_name.replace(\".tsv\", \"\")\n",
    "            cmd_sh = \"python3 {}/AnnotateTablePython3.py -a {}/{} -n rmsk -i {}/{}.tsv -o {}/{}.out.rmsk -u\".format(u_path, u_path, rmsk, path, name, path, name)\n",
    "            args = shlex.split(cmd_sh)\n",
    "            p = subprocess.Popen(args, env=dict(os.environ, PATH=\"/lustrehome/pietrolucamazzacuva/anaconda3/envs/tensorflow-gpu/bin\"))\n",
    "\n",
    "    time.sleep(300)\n",
    "\n",
    "    for name in os.listdir(path):\n",
    "        if name.find(\"rmsk\") != -1:\n",
    "            cmd_sh = \"python3 {}/AnnotateTablePython3.py -a {}/{} -i {}/{} -o {}/{}.refseq -u\".format(u_path, u_path, refseq, path, name, path, name)\n",
    "            args = shlex.split(cmd_sh)\n",
    "            p = subprocess.Popen(args, env=dict(os.environ, PATH=\"/lustrehome/pietrolucamazzacuva/anaconda3/envs/tensorflow-gpu/bin\"))\n",
    "\n",
    "    time.sleep(300)\n",
    "\n",
    "    cols = [\"Region\", \"Position\", \"Class\", \"RMSK-Rep\", \"RMSK-Reg\", \"RefSeq-Rep\", \"RefSeq-Reg\"]\n",
    "    for file_name in os.listdir(path):\n",
    "        if file_name.find(\".refseq\") !=-1:\n",
    "            df = pd.read_table(os.path.join(path, file_name), header=None)\n",
    "            name = file_name.replace(\".out.rmsk.refseq\", \"_annoted.tsv\")\n",
    "            df.columns = cols\n",
    "            df.to_csv(os.path.join(path, name), sep=\"\\t\", index=None)\n",
    "\n",
    "    for file_name in os.listdir(path):\n",
    "        if file_name.find(\"candidates_bona_fide_sites_annoted.tsv\") !=-1:\n",
    "            bona_fide = pd.read_csv(os.path.join(path, file_name), sep=\"\\t\")\n",
    "            rep = bona_fide[(bona_fide.iloc[:, 3] != \"-\") & (bona_fide.iloc[:, 4] != \"-\")]\n",
    "            non_rep = bona_fide[(bona_fide.iloc[:, 3] == \"-\") & (bona_fide.iloc[:, 4] == \"-\")]\n",
    "\n",
    "            del bona_fide\n",
    "\n",
    "            non_rep_n = non_rep[non_rep.iloc[:, 2]==0]\n",
    "            non_rep_p = non_rep[non_rep.iloc[:, 2]==1]\n",
    "\n",
    "            del non_rep\n",
    "\n",
    "            non_rep_p = non_rep_p[(non_rep_p.iloc[:, 5] != \"-\") & (non_rep_p.iloc[:, 6] != \"-\")]\n",
    "            bona_fide = pd.concat([rep, non_rep_n, non_rep_p])\n",
    "\n",
    "            del rep, non_rep_n, non_rep_p\n",
    "\n",
    "            name = file_name.replace(\"candidates_bona_fide_sites_annoted.tsv\", \"bona_fide_sites.tsv\")\n",
    "            bona_fide = bona_fide.sort_values([\"Region\", \"Position\"])\n",
    "            bona_fide.to_csv(os.path.join(path, name), sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf05b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 0\tSites evaluated: 0\tSites evaluated: 0\n",
      "\n",
      "\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "Total evaluated rows: 216398797\n",
      "Total extracted Candidates Editing sites for current sample: 6686\n",
      "[2024-07-26 02:08:59.269623] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:05:51.648213.\n",
      "[2024-07-26 02:08:59.272349] Starting extraction of intervals.\n",
      "[2024-07-26 02:08:59.313647] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_436061877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/6673 [00:00<00:31, 213.35it/s][W::hts_idx_load2] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_436061877.gz.tbi\n",
      "100%|██████████| 6673/6673 [00:18<00:00, 352.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:09:18.320402] Total extracted Editing sites: 2823.\n",
      "[2024-07-26 02:09:18.321805] Features Extraction Finished. Elapsed time 0:00:19.046335.\n",
      "[2024-07-26 02:09:18.340506] Computation Finished. Total Elapsed time: 0:06:10.719114\n",
      "Total evaluated rows: 235536788\n",
      "Total extracted Candidates Editing sites for current sample: 16915\n",
      "[2024-07-26 02:09:32.739629] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:25.118002.\n",
      "[2024-07-26 02:09:32.741382] Starting extraction of intervals.\n",
      "[2024-07-26 02:09:32.754313] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_535670354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/16904 [00:00<01:34, 179.13it/s][W::hts_idx_load2] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_535670354.gz.tbi\n",
      "  2%|▏         | 276/16904 [00:00<00:40, 414.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 236217106\n",
      "Total extracted Candidates Editing sites for current sample: 15740\n",
      "[2024-07-26 02:09:33.617210] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:25.995222.\n",
      "[2024-07-26 02:09:33.619052] Starting extraction of intervals.\n",
      "[2024-07-26 02:09:33.631254] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_773331943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/15728 [00:00<01:20, 194.04it/s]][W::hts_idx_load2] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_773331943.gz.tbi\n",
      " 12%|█▏        | 1835/15728 [00:05<00:40, 344.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 239780038\n",
      "Total extracted Candidates Editing sites for current sample: 8840\n",
      "[2024-07-26 02:09:38.861141] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:31.239291.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 2190/16904 [00:06<00:46, 319.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:09:38.862909] Starting extraction of intervals.\n",
      "[2024-07-26 02:09:38.872090] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_396704193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 864/8828 [00:02<00:21, 374.06it/s]s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 241233789\n",
      "Total extracted Candidates Editing sites for current sample: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 2674/15728 [00:07<00:34, 383.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9315\n",
      "[2024-07-26 02:09:41.287051] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:33.664895."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 3059/16904 [00:08<00:40, 345.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2024-07-26 02:09:41.289096] Starting extraction of intervals.\n",
      "[2024-07-26 02:09:41.299469] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_302610513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1602/8828 [00:04<00:19, 366.54it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 241316303\n",
      "Total extracted Candidates Editing sites for current sample: 19104\n",
      "[2024-07-26 02:09:43.231616] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:06:35.610306.\n",
      "[2024-07-26 02:09:43.233672] Starting extraction of intervals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 3733/16904 [00:10<00:40, 325.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:09:43.247178] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_192318299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8828/8828 [00:23<00:00, 378.64it/s]s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:10:02.225161] Total extracted Editing sites: 3734.\n",
      "[2024-07-26 02:10:02.226623] Features Extraction Finished. Elapsed time 0:00:23.361816.\n",
      "[2024-07-26 02:10:02.271931] Computation Finished. Total Elapsed time: 0:06:54.650107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9304/9304 [00:24<00:00, 374.98it/s]s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:10:06.177406] Total extracted Editing sites: 3958.\n",
      "[2024-07-26 02:10:06.178861] Features Extraction Finished. Elapsed time 0:00:24.887606.\n",
      "[2024-07-26 02:10:06.202314] Computation Finished. Total Elapsed time: 0:06:58.580180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 12100/15728 [00:32<00:09, 365.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15728/15728 [00:42<00:00, 373.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:10:15.745586] Total extracted Editing sites: 6688.\n",
      "[2024-07-26 02:10:15.747250] Features Extraction Finished. Elapsed time 0:00:42.125606.\n",
      "[2024-07-26 02:10:15.783542] Computation Finished. Total Elapsed time: 0:07:08.161574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16904/16904 [00:44<00:00, 377.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:10:17.642503] Total extracted Editing sites: 7089.\n",
      "[2024-07-26 02:10:17.643959] Features Extraction Finished. Elapsed time 0:00:44.900081.\n",
      "[2024-07-26 02:10:17.678892] Computation Finished. Total Elapsed time: 0:07:10.057284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19093/19093 [00:50<00:00, 376.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:10:34.082861] Total extracted Editing sites: 7976.\n",
      "[2024-07-26 02:10:34.084546] Features Extraction Finished. Elapsed time 0:00:50.848787.\n",
      "[2024-07-26 02:10:34.125533] Computation Finished. Total Elapsed time: 0:07:26.504246\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::hts_idx_load2] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_436061877.gz.tbi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "Total evaluated rows: 235536788\n",
      "Total extracted candidates bona fide Sites for outTable_535670354 outTable_396704193 samples: 9105\n",
      "Total candidates positives bona fide Sites for outTable_535670354 outTable_396704193 samples: 6060Total evaluated rows:\n",
      "Total candidates negatives bona fide Sites for outTable_535670354 outTable_396704193 samples: 3045\n",
      " [2024-07-26 02:18:44.158986] Extraction of candidates bonafide sites finished for outTable_535670354 outTable_396704193 samples. Elapsed time: 0:08:09.935500.236217106\n",
      "\n",
      "Total extracted candidates bona fide Sites for outTable_773331943 outTable_302610513 samples: 8961\n",
      "Total candidates positives bona fide Sites for outTable_773331943 outTable_302610513 samples: 5828\n",
      "Total candidates negatives bona fide Sites for outTable_773331943 outTable_302610513 samples: 3133\n",
      "[2024-07-26 02:18:44.166963] Extraction of candidates bonafide sites finished for outTable_773331943 outTable_302610513 samples. Elapsed time: 0:08:09.943346.\n",
      "Total evaluated rows: 241316303\n",
      "Total extracted candidates bona fide Sites for outTable_192318299 outTable_436061877 samples: 7689\n",
      "Total candidates positives bona fide Sites for outTable_192318299 outTable_436061877 samples: 5165\n",
      "Total candidates negatives bona fide Sites for outTable_192318299 outTable_436061877 samples: 2524\n",
      "[2024-07-26 02:19:02.405148] Extraction of candidates bonafide sites finished for outTable_192318299 outTable_436061877 samples. Elapsed time: 0:08:28.181831.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:19:03\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_192318299_outTable_436061877_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 02:19:24\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:19:03\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_773331943_outTable_302610513_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 02:19:26\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:19:03\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_535670354_outTable_396704193_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 02:19:27\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:24:02\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_192318299_outTable_436061877_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 02:24:24\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:24:02\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_773331943_outTable_302610513_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 02:24:27\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:24:02\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/a549/outTable_535670354_outTable_396704193_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 02:24:27\n"
     ]
    }
   ],
   "source": [
    "min_dna_cov = 10\n",
    "min_rna_cov = 50\n",
    "min_AG_rate = 0.01\n",
    "min_G = 3\n",
    "seq_lenght = 101\n",
    "\n",
    "cells = \"a549\"\n",
    "\n",
    "samples, rmsk_file_name, refseq_file_name, filespath = give_inputs(cells)\n",
    "    \n",
    "inputs = []\n",
    "for i in range(len(samples)):\n",
    "    for j in range(len(samples[i])):\n",
    "        inputs.append([os.path.join(filespath, f\"{samples[i][j]}\"), min_G, min_AG_rate, min_rna_cov, seq_lenght])\n",
    "\n",
    "with Pool(9) as pool:\n",
    "    pool.starmap(extraction, inputs)\n",
    "    \n",
    "inputs = []\n",
    "for i in range(3):\n",
    "    inputs.append([samples[i][0], samples[i][1], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov])\n",
    "\n",
    "with Pool(6) as pool:\n",
    "    pool.starmap(candidates_bona_fide_extraction, inputs)     \n",
    "\n",
    "bonafide_identification(filespath, rmsk_file_name, refseq_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74083200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "Total evaluated rows: 194677901\n",
      "Total extracted Candidates Editing sites for current sample: 12129\n",
      "[2024-07-26 02:34:18.217597] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:05:15.016094.\n",
      "[2024-07-26 02:34:18.220105] Starting extraction of intervals.\n",
      "[2024-07-26 02:34:18.236179] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_905657585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2626/12116 [00:08<00:25, 370.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 2671/12116 [00:08<00:24, 393.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 3585/12116 [00:11<00:21, 389.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 3625/12116 [00:11<00:23, 369.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4095/12116 [00:12<00:20, 385.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 4147/12116 [00:12<00:18, 422.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 199831579\n",
      "Total extracted Candidates Editing sites for current sample: 24950\n",
      "[2024-07-26 02:34:31.030527] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:05:27.828328.\n",
      "[2024-07-26 02:34:31.032403] Starting extraction of intervals.\n",
      "[2024-07-26 02:34:31.047963] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_110067244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 4641/12116 [00:13<00:20, 359.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 5323/12116 [00:15<00:16, 410.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 200000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 7332/12116 [00:20<00:12, 380.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1811/24936 [00:07<01:03, 363.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205675117\n",
      "Total extracted Candidates Editing sites for current sample: 12340\n",
      "[2024-07-26 02:34:39.046937] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:05:35.845007.\n",
      "[2024-07-26 02:34:39.048965] Starting extraction of intervals.\n",
      "[2024-07-26 02:34:39.059941] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_364841872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 360/12324 [00:01<00:45, 262.64it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 208788107\n",
      "Total extracted Candidates Editing sites for current sample: 11497\n",
      "[2024-07-26 02:34:41.168633] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:05:37.966320.\n",
      "[2024-07-26 02:34:41.170384] Starting extraction of intervals.\n",
      "[2024-07-26 02:34:41.180118] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_597789462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12116/12116 [00:32<00:00, 369.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:34:51.114058] Total extracted Editing sites: 5265.\n",
      "[2024-07-26 02:34:51.115648] Features Extraction Finished. Elapsed time 0:00:32.893675.\n",
      "[2024-07-26 02:34:51.145426] Computation Finished. Total Elapsed time: 0:05:47.943941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12324/12324 [00:33<00:00, 369.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:35:12.686625] Total extracted Editing sites: 5266.\n",
      "[2024-07-26 02:35:12.688165] Features Extraction Finished. Elapsed time 0:00:33.636295.\n",
      "[2024-07-26 02:35:12.717166] Computation Finished. Total Elapsed time: 0:06:09.515253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11482/11482 [00:32<00:00, 356.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:35:13.478918] Total extracted Editing sites: 4943.\n",
      "[2024-07-26 02:35:13.480383] Features Extraction Finished. Elapsed time 0:00:32.307812.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 14864/24936 [00:42<00:26, 386.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:35:13.507009] Computation Finished. Total Elapsed time: 0:06:10.304713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24936/24936 [01:07<00:00, 367.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:35:39.405683] Total extracted Editing sites: 10159.\n",
      "[2024-07-26 02:35:39.408142] Features Extraction Finished. Elapsed time 0:01:08.373746.\n",
      "[2024-07-26 02:35:39.460398] Computation Finished. Total Elapsed time: 0:06:36.258221\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "Total evaluated rows: 266283468\n",
      "Total extracted Candidates Editing sites for current sample: 56231\n",
      "[2024-07-26 02:36:23.320695] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:07:20.119042.\n",
      "[2024-07-26 02:36:23.323184] Starting extraction of intervals.\n",
      "[2024-07-26 02:36:23.365294] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_208420383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 10399/56216 [00:30<01:57, 388.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 288775068\n",
      "Total extracted Candidates Editing sites for current sample: 39037\n",
      "[2024-07-26 02:36:54.469171] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:07:51.267379.\n",
      "[2024-07-26 02:36:54.470987] Starting extraction of intervals.\n",
      "[2024-07-26 02:36:54.492693] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_572868058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 16466/56216 [00:47<01:44, 380.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 298335470\n",
      "Total extracted Candidates Editing sites for current sample: 68163\n",
      "[2024-07-26 02:37:11.413010] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:08:08.210927."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 5946/39024 [00:16<01:50, 298.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2024-07-26 02:37:11.414780] Starting extraction of intervals.\n",
      "[2024-07-26 02:37:11.447786] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_814257267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 16540/56216 [00:48<02:03, 322.26it/s][W::hts_idx_load2] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_814257267.gz.tbi\n",
      " 30%|███       | 16866/56216 [00:48<01:40, 393.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 298198400\n",
      "Total extracted Candidates Editing sites for current sample: 69467\n",
      "[2024-07-26 02:37:12.543361] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:08:09.341047.\n",
      "[2024-07-26 02:37:12.545044] Starting extraction of intervals."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 349/68149 [00:00<03:02, 371.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 16915/56216 [00:49<01:33, 420.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:37:12.578558] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_530905096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 17001/56216 [00:49<01:34, 417.10it/s][W::hts_idx_load2] The index file is older than the data file: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_530905096.gz.tbi\n",
      " 33%|███▎      | 18281/56216 [00:52<01:40, 376.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 300000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 37090/39024 [01:43<00:05, 362.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 350000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39024/39024 [01:49<00:00, 356.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:38:43.955937] Total extracted Editing sites: 15794.\n",
      "[2024-07-26 02:38:43.957827] Features Extraction Finished. Elapsed time 0:01:49.484880.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 32103/68149 [01:32<01:36, 371.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:38:44.035496] Computation Finished. Total Elapsed time: 0:09:40.833734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56216/56216 [02:38<00:00, 355.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:39:01.786862] Total extracted Editing sites: 23605.\n",
      "[2024-07-26 02:39:01.788743] Features Extraction Finished. Elapsed time 0:02:38.462631.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 37790/69453 [01:49<01:15, 416.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:39:01.899408] Computation Finished. Total Elapsed time: 0:09:58.697789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 40903/69453 [01:57<01:15, 375.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 369524874\n",
      "Total extracted Candidates Editing sites for current sample: 56798\n",
      "[2024-07-26 02:39:10.444545] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:10:07.243209."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 41665/68149 [01:58<01:12, 363.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2024-07-26 02:39:10.446261] Starting extraction of intervals.\n",
      "[2024-07-26 02:39:10.473980] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_599710609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68149/68149 [03:14<00:00, 351.13it/s]\n",
      " 96%|█████████▋| 66946/69453 [03:13<00:07, 319.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:40:25.714782] Total extracted Editing sites: 28704.\n",
      "[2024-07-26 02:40:25.716658] Features Extraction Finished. Elapsed time 0:03:14.299941.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 66979/69453 [03:13<00:08, 297.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:40:25.846722] Computation Finished. Total Elapsed time: 0:11:22.644663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69453/69453 [03:20<00:00, 346.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:40:33.149605] Total extracted Editing sites: 29211.\n",
      "[2024-07-26 02:40:33.151731] Features Extraction Finished. Elapsed time 0:03:20.604811.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 27155/56785 [01:22<01:16, 386.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:40:33.286016] Computation Finished. Total Elapsed time: 0:11:30.083733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56785/56785 [02:50<00:00, 332.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 02:42:01.251908] Total extracted Editing sites: 23062.\n",
      "[2024-07-26 02:42:01.253946] Features Extraction Finished. Elapsed time 0:02:50.805704.\n",
      "[2024-07-26 02:42:01.358765] Computation Finished. Total Elapsed time: 0:12:58.157452\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\tSites evaluated: 0\n",
      "\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "Total evaluated rows: 199831579\n",
      "Total extracted candidates bona fide Sites for outTable_110067244 outTable_597789462 samples: 20000\n",
      "Total candidates positives bona fide Sites for outTable_110067244 outTable_597789462 samples: 16214\n",
      "Total candidates negatives bona fide Sites for outTable_110067244 outTable_597789462 samples: 3786\n",
      "[2024-07-26 02:49:27.021301] Extraction of candidates bonafide sites finished for outTable_110067244 outTable_597789462 samples. Elapsed time: 0:07:25.446681.\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "Total evaluated rows: 288775068\n",
      "Total extracted candidates bona fide Sites for outTable_572868058 outTable_364841872 samples: 21935\n",
      "Total candidates positives bona fide Sites for outTable_572868058 outTable_364841872 samples: 18063\n",
      "Total candidates negatives bona fide Sites for outTable_572868058 outTable_364841872 samples: 3872\n",
      "[2024-07-26 02:52:36.164223] Extraction of candidates bonafide sites finished for outTable_572868058 outTable_364841872 samples. Elapsed time: 0:10:34.590050.\n",
      "Total evaluated rows: 266283468\n",
      "Total extracted candidates bona fide Sites for outTable_208420383 outTable_905657585 samples: 31903\n",
      "Total candidates positives bona fide Sites for outTable_208420383 outTable_905657585 samples: 28224\n",
      "Total candidates negatives bona fide Sites for outTable_208420383 outTable_905657585 samples: 3679\n",
      "[2024-07-26 02:52:37.218980] Extraction of candidates bonafide sites finished for outTable_208420383 outTable_905657585 samples. Elapsed time: 0:10:35.644917.\n",
      "\tSites evaluated: 300000000\n",
      "Total evaluated rows: 298335470\n",
      "Total extracted candidates bona fide Sites for outTable_814257267 outTable_364841872 samples: 33474\n",
      "Total candidates positives bona fide Sites for outTable_814257267 outTable_364841872 samples: 29613\n",
      "Total candidates negatives bona fide Sites for outTable_814257267 outTable_364841872 samples: 3861\n",
      "[2024-07-26 02:54:02.763578] Extraction of candidates bonafide sites finished for outTable_814257267 outTable_364841872 samples. Elapsed time: 0:12:01.189113.\n",
      "Total evaluated rows: 298198400\n",
      "Total extracted candidates bona fide Sites for outTable_530905096 outTable_597789462 samples: 34914\n",
      "Total candidates positives bona fide Sites for outTable_530905096 outTable_597789462 samples: 31125\n",
      "Total candidates negatives bona fide Sites for outTable_530905096 outTable_597789462 samples: 3789\n",
      "[2024-07-26 02:54:12.145751] Extraction of candidates bonafide sites finished for outTable_530905096 outTable_597789462 samples. Elapsed time: 0:12:10.571031.\n",
      "\tSites evaluated: 350000000\n",
      "Total evaluated rows: 369524874\n",
      "Total extracted candidates bona fide Sites for outTable_599710609 outTable_905657585 samples: 25612\n",
      "Total candidates positives bona fide Sites for outTable_599710609 outTable_905657585 samples: 21923\n",
      "Total candidates negatives bona fide Sites for outTable_599710609 outTable_905657585 samples: 3689\n",
      "[2024-07-26 02:55:39.930359] Extraction of candidates bonafide sites finished for outTable_599710609 outTable_905657585 samples. Elapsed time: 0:13:38.356425.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:55:42\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_110067244_outTable_597789462_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 02:56:37\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:55:42\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_572868058_outTable_364841872_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 02:56:41\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:55:42\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_599710609_outTable_905657585_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 02:56:51\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:55:42\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_208420383_outTable_905657585_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 02:57:08\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:55:42\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_814257267_outTable_364841872_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 02:57:12\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 02:55:42\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_530905096_outTable_597789462_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 02:57:17\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 03:00:40\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_110067244_outTable_597789462_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 03:01:51\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 03:00:40\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_572868058_outTable_364841872_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 03:01:59\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 03:00:40\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_599710609_outTable_905657585_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 03:02:10\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 03:00:40\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_208420383_outTable_905657585_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 03:02:34\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 03:00:40\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_814257267_outTable_364841872_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 03:02:39\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 03:00:40\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK293T/outTable_530905096_outTable_597789462_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 03:02:45\n"
     ]
    }
   ],
   "source": [
    "min_dna_cov = 10\n",
    "min_rna_cov = 50\n",
    "min_AG_rate = 0.01\n",
    "min_G = 3\n",
    "seq_lenght = 101\n",
    "\n",
    "cells = \"HEK293T\"\n",
    "\n",
    "samples, rmsk_file_name, refseq_file_name, filespath = give_inputs(cells)\n",
    "\n",
    "inputs = []\n",
    "for i in range(len(samples)):\n",
    "    for j in range(len(samples[i])):\n",
    "        inputs.append([os.path.join(filespath, f\"{samples[i][j]}\"), min_G, min_AG_rate, min_rna_cov, seq_lenght])\n",
    "\n",
    "with Pool(9) as pool:\n",
    "    pool.starmap(extraction, inputs)\n",
    "    \n",
    "inputs = []\n",
    "for i in range(3):\n",
    "    inputs.append([samples[i][0], samples[i][1], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov])\n",
    "    inputs.append([samples[i][2], samples[i][1], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov])\n",
    "\n",
    "with Pool(6) as pool:\n",
    "    pool.starmap(candidates_bona_fide_extraction, inputs)     \n",
    "\n",
    "bonafide_identification(filespath, rmsk_file_name, refseq_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ac79015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\tSites evaluated: 0\n",
      "\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "Total evaluated rows: 419443529\n",
      "Total extracted Candidates Editing sites for current sample: 5327\n",
      "[2024-07-26 01:13:09.001579] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:11:10.412262.\n",
      "[2024-07-26 01:13:09.003465] Starting extraction of intervals.\n",
      "[2024-07-26 01:13:09.020038] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_718392497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 884/5315 [00:07<00:17, 255.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 422584480\n",
      "Total extracted Candidates Editing sites for current sample: 13236\n",
      "[2024-07-26 01:13:16.339988] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:11:17.750366.\n",
      "[2024-07-26 01:13:16.342021] Starting extraction of intervals.\n",
      "[2024-07-26 01:13:16.356252] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_181728208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5315/5315 [00:26<00:00, 202.84it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 01:13:35.303211] Total extracted Editing sites: 2275.\n",
      "[2024-07-26 01:13:35.304847] Features Extraction Finished. Elapsed time 0:00:26.299238.\n",
      "[2024-07-26 01:13:35.322283] Computation Finished. Total Elapsed time: 0:11:36.732979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 12596/13223 [00:40<00:01, 358.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 450000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 12877/13223 [00:41<00:00, 362.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 450000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13223/13223 [00:42<00:00, 308.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 01:13:59.317995] Total extracted Editing sites: 5727.\n",
      "[2024-07-26 01:13:59.319477] Features Extraction Finished. Elapsed time 0:00:42.975225.\n",
      "[2024-07-26 01:13:59.351890] Computation Finished. Total Elapsed time: 0:12:00.762286\n",
      "\tSites evaluated: 450000000\n",
      "\tSites evaluated: 450000000\n",
      "Total evaluated rows: 452378572\n",
      "Total extracted Candidates Editing sites for current sample: 8716\n",
      "[2024-07-26 01:14:05.888374] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:12:07.299556.\n",
      "[2024-07-26 01:14:05.889963] Starting extraction of intervals.\n",
      "[2024-07-26 01:14:05.913438] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_724242056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 4758/8703 [00:21<00:13, 289.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 469580145\n",
      "Total extracted Candidates Editing sites for current sample: 6749\n",
      "[2024-07-26 01:14:28.567701] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:12:29.978706.\n",
      "[2024-07-26 01:14:28.569167] Starting extraction of intervals.\n",
      "[2024-07-26 01:14:28.580087] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_816573740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8703/8703 [00:36<00:00, 236.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 01:14:42.827701] Total extracted Editing sites: 3636.\n",
      "[2024-07-26 01:14:42.829221] Features Extraction Finished. Elapsed time 0:00:36.937226.\n",
      "[2024-07-26 01:14:42.851109] Computation Finished. Total Elapsed time: 0:12:44.262308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 6106/6737 [00:23<00:01, 349.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated rows: 483808594\n",
      "Total extracted Candidates Editing sites for current sample: 12924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 6142/6737 [00:23<00:02, 287.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 01:14:52.321966] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:12:53.732797.\n",
      "[2024-07-26 01:14:52.324085] Starting extraction of intervals.\n",
      "[2024-07-26 01:14:52.345980] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_580067564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6737/6737 [00:26<00:00, 253.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 01:14:55.207704] Total extracted Editing sites: 2909.\n",
      "[2024-07-26 01:14:55.209059] Features Extraction Finished. Elapsed time 0:00:26.638099.\n",
      "[2024-07-26 01:14:55.227999] Computation Finished. Total Elapsed time: 0:12:56.639017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 8193/12912 [00:30<00:18, 250.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSites evaluated: 500000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12912/12912 [00:47<00:00, 273.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 01:15:39.661464] Total extracted Editing sites: 5601.\n",
      "[2024-07-26 01:15:39.663265] Features Extraction Finished. Elapsed time 0:00:47.337177.\n",
      "[2024-07-26 01:15:39.700134] Computation Finished. Total Elapsed time: 0:13:41.110998\n",
      "Total evaluated rows: 519011879\n",
      "Total extracted Candidates Editing sites for current sample: 8560\n",
      "[2024-07-26 01:15:53.493626] Extraction of Editing Candidates finished for current sample. Elapsed time: 0:13:54.903883.\n",
      "[2024-07-26 01:15:53.495171] Starting extraction of intervals.\n",
      "[2024-07-26 01:15:53.505571] Loading reditable with tabix and pysam: /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_854894021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8542/8542 [00:41<00:00, 206.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-26 01:16:34.879787] Total extracted Editing sites: 3867.\n",
      "[2024-07-26 01:16:34.881134] Features Extraction Finished. Elapsed time 0:00:41.384062.\n",
      "[2024-07-26 01:16:34.905574] Computation Finished. Total Elapsed time: 0:14:36.315844\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 0\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 50000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 100000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 150000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 200000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 250000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 300000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 350000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "\tSites evaluated: 400000000\n",
      "Total evaluated rows: 422584480\n",
      "Total extracted candidates bona fide Sites for outTable_181728208 outTable_854894021 samples: 14812\n",
      "Total candidates positives bona fide Sites for outTable_181728208 outTable_854894021 samples: 10562\n",
      "Total candidates negatives bona fide Sites for outTable_181728208 outTable_854894021 samples: 4250\n",
      "[2024-07-26 01:30:31.131245] Extraction of candidates bonafide sites finished for outTable_181728208 outTable_854894021 samples. Elapsed time: 0:13:56.082078.\n",
      "\tSites evaluated: 450000000\n",
      "\tSites evaluated: 450000000\n",
      "Total evaluated rows: 452378572\n",
      "Total extracted candidates bona fide Sites for outTable_724242056 outTable_816573740 samples: 9300\n",
      "Total candidates positives bona fide Sites for outTable_724242056 outTable_816573740 samples: 5928\n",
      "Total candidates negatives bona fide Sites for outTable_724242056 outTable_816573740 samples: 3372\n",
      "[2024-07-26 01:31:00.890158] Extraction of candidates bonafide sites finished for outTable_724242056 outTable_816573740 samples. Elapsed time: 0:14:25.841228.\n",
      "Total evaluated rows: 483808594\n",
      "Total extracted candidates bona fide Sites for outTable_580067564 outTable_718392497 samples: 8307\n",
      "Total candidates positives bona fide Sites for outTable_580067564 outTable_718392497 samples: 5574\n",
      "Total candidates negatives bona fide Sites for outTable_580067564 outTable_718392497 samples: 2733\n",
      "[2024-07-26 01:31:49.721793] Extraction of candidates bonafide sites finished for outTable_580067564 outTable_718392497 samples. Elapsed time: 0:15:14.672711.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 01:31:51\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_580067564_outTable_718392497_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 01:32:13\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 01:31:51\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_724242056_outTable_816573740_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 01:32:15\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 01:31:51\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_181728208_outTable_854894021_candidates_bona_fide_sites.out.rmsk\n",
      "Script time --> END: 26/07/2024 01:32:29\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 01:36:50\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_580067564_outTable_718392497_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 01:37:14\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 01:36:50\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_724242056_outTable_816573740_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 01:37:16\n",
      "Pysam version used: 0.15.4\n",
      "Script time --> START: 26/07/2024 01:36:50\n",
      "Table saved on /lustrehome/pietrolucamazzacuva/filezilla-recas/tissues/independent_datasets/HEK/outTable_181728208_outTable_854894021_candidates_bona_fide_sites.out.rmsk.refseq\n",
      "Script time --> END: 26/07/2024 01:37:31\n"
     ]
    }
   ],
   "source": [
    "min_dna_cov = 10\n",
    "min_rna_cov = 30\n",
    "min_AG_rate = 0.01\n",
    "min_G = 2\n",
    "seq_lenght = 101\n",
    "\n",
    "cells = \"HEK\"\n",
    "\n",
    "samples, rmsk_file_name, refseq_file_name, filespath = give_inputs(cells)\n",
    "    \n",
    "inputs = []\n",
    "for i in range(len(samples)):\n",
    "    for j in range(len(samples[i])):\n",
    "        inputs.append([os.path.join(filespath, f\"{samples[i][j]}\"), min_G, min_AG_rate, min_rna_cov, seq_lenght])\n",
    "\n",
    "with Pool(9) as pool:\n",
    "    pool.starmap(extraction, inputs)\n",
    "    \n",
    "inputs = []\n",
    "for i in range(3):\n",
    "    inputs.append([samples[i][0], samples[i][1], filespath, cells, min_G, min_AG_rate, min_dna_cov, min_rna_cov])\n",
    "\n",
    "with Pool(6) as pool:\n",
    "    pool.starmap(candidates_bona_fide_extraction, inputs)     \n",
    "\n",
    "bonafide_identification(filespath, rmsk_file_name, refseq_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
